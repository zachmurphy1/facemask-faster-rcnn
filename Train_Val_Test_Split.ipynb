{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train-Val-Test Split.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyObrYsGD9OksFb3R5wgCemu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zachmurphy1/facemask-faster-rcnn/blob/main/Train_Val_Test_Split.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmMfZtMHOKWy"
      },
      "source": [
        "# Train-val-test split\n",
        "\n",
        "This notebook performs a train-val-test split on the raw images and annotations folders.\n",
        "\n",
        "##Input\n",
        "Images and annotations folder, each containing respective data at the top level and sequentially numbered. Originally obtained from https://www.kaggle.com/andrewmvd/face-mask-detection.\n",
        "```\n",
        "facemask_data/images\n",
        "facemask_data/annotations\n",
        "```\n",
        "\n",
        "\n",
        "##Output\n",
        "Images and annotations folders for each set. Each set gets its own folder.\n",
        "```\n",
        "Train:\n",
        "facemask_data/images/train\n",
        "facemask_data/images/train/images\n",
        "facemask_data/images/train/annotations\n",
        "\n",
        "Val:\n",
        "facemask_data/images/val\n",
        "facemask_data/imagesval/images\n",
        "facemask_data/images/val/annotations\n",
        "\n",
        "Test:\n",
        "facemask_data/images/test\n",
        "facemask_data/images/test/images\n",
        "facemask_data/images/test/annotations\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6xIoUu9MMBh"
      },
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import shutil, os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV5SjU8Vx7AU"
      },
      "source": [
        "# Mount data directory\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "%cd /content/gdrive/My\\ Drive/facemask-faster-rcnn/\n",
        "\n",
        "DATADIR = 'facemask_data'\n",
        "ANNDIR = DATADIR + '/annotations'\n",
        "IMGDIR = DATADIR + '/images'\n",
        "PREFIX = 'maksssksksss'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxElgYjyyO4c"
      },
      "source": [
        "# Set total n, train/val/test split, and seed\n",
        "n = 853\n",
        "split_frac = {\n",
        "    'train':0.6,\n",
        "    'val':0.2,\n",
        "    'test':0.2\n",
        "    }\n",
        "seed=0\n",
        "assert sum(split_frac.values()) == 1, 'split_frac components need to sum to 1'\n",
        "\n",
        "# Randomly order indices\n",
        "np.random.seed(seed)\n",
        "to_split = np.arange(n)\n",
        "np.random.shuffle(to_split)\n",
        "np.random.seed(None)\n",
        "\n",
        "# Split indices according to split fractions\n",
        "SPLIT_IDX = {\n",
        "    'train':list(to_split[0:int(n*split_frac['train'])]),\n",
        "    'val':list(to_split[int(n*split_frac['train']):int(n*(split_frac['train']+split_frac['val']))]),\n",
        "    'test':list(to_split[int(n*(split_frac['train']+split_frac['val'])):])\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93PX5fWP8ODz"
      },
      "source": [
        "# Save datasets to different directories\n",
        "for ds in ['train', 'val','test']:\n",
        "  print(ds)\n",
        "  # Get idxs\n",
        "  idxs = SPLIT_IDX[ds]\n",
        "\n",
        "  # Set image dirs\n",
        "  origin_img = IMGDIR\n",
        "  destination_img = DATADIR + '/' + ds + '/images'\n",
        "\n",
        "  # Set ann dirs\n",
        "  origin_ann = ANNDIR\n",
        "  destination_ann = DATADIR + '/' + ds + '/annotations'\n",
        "\n",
        "  # Create dirs\n",
        "  os.makedirs(DATADIR + '/' + ds, exist_ok=True)\n",
        "  os.makedirs(destination_img, exist_ok=True)\n",
        "  os.makedirs(destination_ann, exist_ok=True)\n",
        "\n",
        "  # For each idx, copy image and ann from origin to target dir\n",
        "  for i, idx in enumerate(idxs):\n",
        "    shutil.copy(origin_img + '/' + PREFIX + str(idx) + '.png', destination_img + '/' + str(i) + '.png')\n",
        "    shutil.copy(origin_ann + '/' + PREFIX + str(idx) + '.xml', destination_ann + '/' + str(i) + '.xml')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}