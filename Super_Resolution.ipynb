{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Super Resolution",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMITphgaw7QJtchKkRRwNkq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zachmurphy1/facemask-faster-rcnn/blob/main/Super_Resolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxOWkosDh18h"
      },
      "source": [
        "# Super resolution\n",
        "This notebook implements and trains a super resolution network according to a SRResNet architecture for 4x upscaling. Train data is 5k 128x128 px images of faces from the Flickr Faces HQ (FFHQ) dataset. Val data is 1k images from the FFHQ not in the train set.\n",
        "\n",
        "## Input\n",
        "Train and val images\n",
        "```\n",
        "sr_training/128_train/\n",
        "sr_training/128_val/\n",
        "```\n",
        "\n",
        "## Output\n",
        "Trained SR network\n",
        "```\n",
        "sr_training/sr_model.pkl\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxppNCcXFFGl"
      },
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pickle\n",
        "import sys, os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "from PIL import Image\n",
        "from bs4 import BeautifulSoup\n",
        "import torch, torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yAMyd8zK0bA",
        "outputId": "069bddc7-ad8d-4a64-c557-d4edc9791da9"
      },
      "source": [
        "# Mount data directory\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "%cd /content/gdrive/My\\ Drive/facemask-faster-rcnn/\n",
        "\n",
        "SRDATADIR = 'sr_training/128_train/'\n",
        "SRDATADIR_VAL = 'sr_training/128_val/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVuF3EYzanx3"
      },
      "source": [
        "## Dataset class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5DxK_-v_1Oi"
      },
      "source": [
        "class SRDataset(Dataset):\n",
        "  def __init__(self, mode='train'):\n",
        "    if mode=='train':\n",
        "      self.data_dir = SRDATADIR\n",
        "    elif mode=='val':\n",
        "      self.data_dir = SRDATADIR_VAL\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(next(os.walk(self.data_dir))[2])\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    img = Image.open(SRDATADIR + f'{idx:05d}' + '.png').convert('RGB')\n",
        "    to_tensor = transforms.ToTensor()\n",
        "    img = to_tensor(img)\n",
        "\n",
        "    # Color jitter and random horizontal flips\n",
        "    augmentations = torchvision.transforms.Compose([torchvision.transforms.RandomHorizontalFlip(),torchvision.transforms.ColorJitter()])\n",
        "    img = augmentations(img)\n",
        "\n",
        "    # Downscale by factor of 4\n",
        "    p = img\n",
        "    scale = 0.25\n",
        "    downscale = torchvision.transforms.Resize((int(p.shape[1]*scale),int(p.shape[2]*scale)),interpolation=Image.BICUBIC)\n",
        "    p = downscale(p)\n",
        "    return p, img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXoZz2eCbqjj"
      },
      "source": [
        "## SRResNet class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f3i1rx9ZPov"
      },
      "source": [
        "class Bblock(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Bblock,self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(64,64,(3,3),stride=1,padding=1)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    self.prelu = nn.PReLU(64)\n",
        "    self.conv2 = nn.Conv2d(64,64,(3,3),stride=1,padding=1)\n",
        "    self.bn2 = nn.BatchNorm2d(64)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    skip = x\n",
        "    out = self.conv1(x)\n",
        "    out = self.bn1(out)\n",
        "    out = self.prelu(out)\n",
        "    out = self.conv2(out)\n",
        "    out = self.bn2(out)\n",
        "    out = out + skip\n",
        "    return out\n",
        "\n",
        "\n",
        "class Upscale(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Upscale,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(64,256,(3,3),stride=1,padding=1)\n",
        "    self.pixelShuffle = nn.PixelShuffle(2)\n",
        "    self.prelu = nn.PReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.conv1(x)\n",
        "    out = self.pixelShuffle(out)\n",
        "    out = self.prelu(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "class SRNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SRNetwork,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3,64,(9,9),stride=1,padding=4)\n",
        "    self.prelu = nn.PReLU()\n",
        "\n",
        "    bres_modules = []\n",
        "    for i in range(16):\n",
        "      bres_modules.append(Bblock())\n",
        "    self.Bres = nn.Sequential(*bres_modules)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(64,64,(3,3),stride=1,padding=1)\n",
        "    self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "    self.upscale1 = Upscale()\n",
        "    self.upscale2 = Upscale()\n",
        "\n",
        "    self.conv3 = nn.Conv2d(64,3,(9,9),stride=1,padding=4)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.conv1(x)\n",
        "    out = self.prelu(out)\n",
        "    skip = out\n",
        "    out = self.Bres(out)\n",
        "    out = self.conv2(out)\n",
        "    out = self.bn2(out)\n",
        "    out = out + skip\n",
        "\n",
        "    out = self.upscale1(out)\n",
        "    out = self.upscale2(out)\n",
        "\n",
        "    out = self.conv3(out)\n",
        "    return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcuwXmJ7bzY9"
      },
      "source": [
        "## Image show function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8k7GUT_owGW"
      },
      "source": [
        "def showImg(images):\n",
        "  with torch.no_grad():\n",
        "    fig, ax = plt.subplots(1,len(images), figsize=(20,60))\n",
        "    for i in range(len(images)):\n",
        "      img_t = torch.transpose(torch.transpose(images[i],0,2),0,1).cpu()\n",
        "      img_t = torch.clamp(img_t,0,1)\n",
        "      ax[i].imshow(img_t)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRjMW3oyb7Bi"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MukHGdbRQ2KS"
      },
      "source": [
        "# Hyperparameters\n",
        "lr = 1e-4\n",
        "batch_size = 16\n",
        "max_epochs = 160\n",
        "\n",
        "# Model\n",
        "model = SRNetwork()\n",
        "model = model.cuda()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=1e-4)\n",
        "\n",
        "# Loss\n",
        "loss_fxn = nn.MSELoss()\n",
        "\n",
        "srData = SRDataset(mode='train')\n",
        "srValData = SRDataset(mode='val')\n",
        "srLoader = DataLoader(srData, batch_size=batch_size, pin_memory=True, shuffle=True)\n",
        "srValLoader = DataLoader(srValData, batch_size=batch_size, pin_memory=True, shuffle=True)\n",
        "\n",
        "\n",
        "# Train loop\n",
        "minibatch_losses = []\n",
        "epoch_losses = []\n",
        "val_losses = []\n",
        "for epoch in range(max_epochs):\n",
        "  epoch_loss = 0\n",
        "  batch_count = 0\n",
        "  for x, y in srLoader:\n",
        "    if torch.cuda.is_available():\n",
        "      x = x.cuda()\n",
        "      y = y.cuda()\n",
        "\n",
        "    # Get pred\n",
        "    yhat = model(x)\n",
        "\n",
        "    # Get loss and backprop\n",
        "    optimizer.zero_grad()\n",
        "    loss = loss_fxn(yhat,y)\n",
        "    batch_count += 1\n",
        "    sys.stdout.write('\\rEpoch {} (Batch {}/{}) Loss: {:.8f}'.format(epoch,batch_count,len(srLoader), loss))\n",
        "    sys.stdout.flush()\n",
        "    minibatch_losses.append(loss)\n",
        "    epoch_loss += loss\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  # Val loss\n",
        "  with torch.no_grad():\n",
        "    val_loss = 0\n",
        "    for x, y in srValLoader:\n",
        "      if torch.cuda.is_available():\n",
        "        x = x.cuda()\n",
        "        y = y.cuda()\n",
        "\n",
        "      # Get pred\n",
        "      yhat = model(x)\n",
        "\n",
        "      # Get loss and backprop\n",
        "      optimizer.zero_grad()\n",
        "      loss = loss_fxn(yhat,y)\n",
        "      val_loss += loss\n",
        "\n",
        "    # Print\n",
        "    epoch_loss /= len(srLoader)\n",
        "    val_loss /= len(srValLoader)\n",
        "    print('Epoch', epoch, 'Train Loss',epoch_loss, 'Val Loss', val_loss)\n",
        "    showImg([x[0],yhat[0],y[0]])\n",
        "    epoch_losses.append(epoch_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxBNG-7zcrst"
      },
      "source": [
        "## Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7jd5znhBoCZ"
      },
      "source": [
        "import pickle\n",
        "with open('sr_training/sr_model.pkl', 'rb') as f:\n",
        "  model = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfuO3_YIczhZ"
      },
      "source": [
        "## Test model on face mask images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Zf4ODvF6jEug"
      },
      "source": [
        "s=0\n",
        "for i in range(s,s+100):\n",
        "  print(i)\n",
        "  img = Image.open('facemask_data/images/maksssksksss{}.png'.format(i)).convert('RGB')\n",
        "  to_tensor = transforms.ToTensor()\n",
        "  img = to_tensor(img)\n",
        "  sr_pred = model(img.unsqueeze(0).cuda())\n",
        "  showImg([img,sr_pred[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rJk3ug_eHGc"
      },
      "source": [
        "## Save an example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0qJKG3Fgiz-"
      },
      "source": [
        "i=64\n",
        "img = Image.open('facemask_data/images/maksssksksss{}.png'.format(i)).convert('RGB')\n",
        "to_tensor = transforms.ToTensor()\n",
        "to_image = transforms.ToPILImage()\n",
        "img = to_tensor(img)\n",
        "sr_pred = model(img.unsqueeze(0).cuda())\n",
        "\n",
        "img = to_image(img)\n",
        "img.save('sr_example_LR.png')\n",
        "sr_pred = to_image(torch.clip(sr_pred[0],0,1))\n",
        "sr_pred.save('sr_example_HR.png')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}